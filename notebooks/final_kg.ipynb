{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3sW5m2acavQ",
        "outputId": "d08f556f-0203-4250-ecec-9607f5541b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.34.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading groq-0.34.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.34.1\n"
          ]
        }
      ],
      "source": [
        "!pip install groq pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V4tkrHrrczv3"
      },
      "outputs": [],
      "source": [
        "import os, json, re\n",
        "import pandas as pd\n",
        "from groq import Groq\n",
        "from getpass import getpass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uXgqmQHc2jj",
        "outputId": "22e88a18-7b8c-4097-b0c1-42adecf28745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GROQ_API_KEY: ··········\n",
            "ModelListResponse(data=[Model(id='whisper-large-v3', created=1693721698, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None, max_completion_tokens=448), Model(id='meta-llama/llama-guard-4-12b', created=1746743847, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=1024), Model(id='whisper-large-v3-turbo', created=1728413088, object='model', owned_by='OpenAI', active=True, context_window=448, public_apps=None, max_completion_tokens=448), Model(id='meta-llama/llama-4-maverick-17b-128e-instruct', created=1743877158, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='moonshotai/kimi-k2-instruct-0905', created=1757046093, object='model', owned_by='Moonshot AI', active=True, context_window=262144, public_apps=None, max_completion_tokens=16384), Model(id='meta-llama/llama-4-scout-17b-16e-instruct', created=1743874824, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='meta-llama/llama-prompt-guard-2-86m', created=1748632165, object='model', owned_by='Meta', active=True, context_window=512, public_apps=None, max_completion_tokens=512), Model(id='moonshotai/kimi-k2-instruct', created=1752435491, object='model', owned_by='Moonshot AI', active=True, context_window=131072, public_apps=None, max_completion_tokens=16384), Model(id='meta-llama/llama-prompt-guard-2-22m', created=1748632101, object='model', owned_by='Meta', active=True, context_window=512, public_apps=None, max_completion_tokens=512), Model(id='openai/gpt-oss-safeguard-20b', created=1761708789, object='model', owned_by='OpenAI', active=True, context_window=131072, public_apps=None, max_completion_tokens=65536), Model(id='openai/gpt-oss-20b', created=1754407957, object='model', owned_by='OpenAI', active=True, context_window=131072, public_apps=None, max_completion_tokens=65536), Model(id='llama-3.3-70b-versatile', created=1733447754, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=32768), Model(id='groq/compound', created=1756949530, object='model', owned_by='Groq', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='llama-3.1-8b-instant', created=1693721698, object='model', owned_by='Meta', active=True, context_window=131072, public_apps=None, max_completion_tokens=131072), Model(id='playai-tts', created=1740682771, object='model', owned_by='PlayAI', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='playai-tts-arabic', created=1740682783, object='model', owned_by='PlayAI', active=True, context_window=8192, public_apps=None, max_completion_tokens=8192), Model(id='qwen/qwen3-32b', created=1748396646, object='model', owned_by='Alibaba Cloud', active=True, context_window=131072, public_apps=None, max_completion_tokens=40960), Model(id='openai/gpt-oss-120b', created=1754408224, object='model', owned_by='OpenAI', active=True, context_window=131072, public_apps=None, max_completion_tokens=65536), Model(id='groq/compound-mini', created=1756949707, object='model', owned_by='Groq', active=True, context_window=131072, public_apps=None, max_completion_tokens=8192), Model(id='allam-2-7b', created=1737672203, object='model', owned_by='SDAIA', active=True, context_window=4096, public_apps=None, max_completion_tokens=4096)], object='list')\n"
          ]
        }
      ],
      "source": [
        "api = getpass(\"Enter GROQ_API_KEY: \")\n",
        "os.environ[\"GROQ_API_KEY\"] = api\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "print(client.models.list())  # check key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1bfVpxWqdald"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    \"faculty\": \"faculty_page.txt\",\n",
        "    \"phd\": \"phd_iiserb_page_clean.txt\",\n",
        "    \"postdocs\": \"postdocs_page_clean.txt\",\n",
        "    \"research_groups\": \"researchGroups_clean.txt\",\n",
        "    \"bsms_3rd\": \"bsms_3rd_year_page_clean.txt\",\n",
        "    \"bsms_4th\": \"bsms_4th_year_page_clean.txt\",\n",
        "    \"bsms_5th\": \"ms_5th_year_page_clean.txt\"\n",
        "}\n",
        "\n",
        "combined_text = \"\"\n",
        "\n",
        "for label, file in files.items():\n",
        "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read().strip()\n",
        "        combined_text += f\"\\n\\n### PAGE: {label.upper()} ###\\n{text}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpmJzUPueL-f",
        "outputId": "7e8bd1b2-1288-4eca-afcf-045667909bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pages: ['faculty', 'phd', 'postdocs', 'research_groups', 'bsms_3rd', 'bsms_4th', 'bsms_5th']\n",
            "\n",
            "\n",
            "### PAGE: FACULTY ###\n",
            "----------------------------------------\n",
            "Name: Vaibhav Kumar\n",
            "Role: Assistant Professor\n",
            "Email(s): vaibhav@iiserb.ac.in\n",
            "Phone: +91 755 269 2681\n",
            "Research Areas:\n",
            " - Geospatial Artificial Intelligence(GeoAI)\n",
            " - 3D GIS\n",
            " - Urban Informatics. HomePage\n",
            "Homepage: https://sites.google.com/view/vaibhavkumar1/home\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "Name: Tanmay Basu [Dept. Head]\n",
            "Role: Assistant Professor\n",
            "Email(s): hod_dse@iiserb.ac.in,, tanmay@iiserb.ac.in\n",
            "Phone: +91 755 269 2683\n",
            "Research Areas:\n",
            " - Biomedical Informatics\n",
            " - Information Extraction\n",
            " - Machine Learning\n",
            " - Natural Language Processing (NLP)\n",
            " - Text Mining. HomePage\n",
            "Homepage: https://sites.google.com/view/tanmaybasu/\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "Name: Jasabanta Patro\n",
            "Role: Assistant Professor\n",
            "Email(s): jpatro@iiserb.ac.in\n",
            "Phone: +91 755 269 2687\n",
            "Research Areas:\n",
            " - Natural Language Processing (NLP). HomePage\n",
            "Homepa\n"
          ]
        }
      ],
      "source": [
        "print(\"Loaded pages:\", list(files.keys()))\n",
        "print(combined_text[:1000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL_gGeb5fDgI"
      },
      "source": [
        "adding schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gatfzvJ3eOjJ"
      },
      "outputs": [],
      "source": [
        "schema_prompt = \"\"\"\n",
        "You are extracting structured entities to build a clean Knowledge Graph for IISER Bhopal.\n",
        "\n",
        "# =====================================================\n",
        "#                  JSON NODE SCHEMA\n",
        "# =====================================================\n",
        "\n",
        "{\n",
        "  \"Student\": {\n",
        "    \"id\": \"unique student identifier\",\n",
        "    \"name\": \"full name\",\n",
        "    \"type\": \"BS | MS | PhD | PostDoc\",\n",
        "    \"roll_no\": \"official roll number\",\n",
        "    \"email\": \"email ID\",\n",
        "    \"department\": \"department ID\",\n",
        "    \"linkedin\": \"LinkedIn URL\",\n",
        "    \"github\": \"GitHub URL\",\n",
        "    \"research_group\": \"research group ID\",\n",
        "    \"guide\": \"faculty ID\"\n",
        "  },\n",
        "\n",
        "  \"Faculty\": {\n",
        "    \"id\": \"unique faculty identifier\",\n",
        "    \"name\": \"full name\",\n",
        "    \"email\": \"email ID\",\n",
        "    \"department\": \"department ID\",\n",
        "    \"position\": \"Professor | Associate Professor | Assistant Professor\",\n",
        "    \"joined_year\": \"year of joining\"\n",
        "  },\n",
        "\n",
        "  \"ResearchGroup\": {\n",
        "    \"id\": \"unique research group ID\",\n",
        "    \"name\": \"research group name\",\n",
        "    \"department\": \"department ID\",\n",
        "    \"head\": \"faculty ID\",\n",
        "    \"website\": \"homepage URL\"\n",
        "  },\n",
        "\n",
        "  \"Department\": {\n",
        "    \"id\": \"unique department ID\",\n",
        "    \"name\": \"department name\",\n",
        "    \"institute\": \"institute ID\",\n",
        "    \"hod\": \"faculty ID\"\n",
        "  },\n",
        "\n",
        "  \"Institute\": {\n",
        "    \"id\": \"unique institute ID\",\n",
        "    \"name\": \"institute name\",\n",
        "    \"director\": \"director name\",\n",
        "    \"location\": \"city, state\",\n",
        "    \"established\": \"year\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# =====================================================\n",
        "#                RELATIONSHIP SCHEMA\n",
        "# =====================================================\n",
        "\n",
        "{\n",
        "  \"belongsTo\": {\n",
        "    \"subject\": [\"Student\", \"Faculty\", \"ResearchGroup\"],\n",
        "    \"object\": [\"Department\"]\n",
        "  },\n",
        "  \"partOf\": {\n",
        "    \"subject\": [\"Department\"],\n",
        "    \"object\": [\"Institute\"]\n",
        "  },\n",
        "  \"heads\": {\n",
        "    \"subject\": [\"Faculty\"],\n",
        "    \"object\": [\"Department\", \"ResearchGroup\"]\n",
        "  },\n",
        "  \"guidedBy\": {\n",
        "    \"subject\": [\"Student\"],\n",
        "    \"object\": [\"Faculty\"]\n",
        "  },\n",
        "  \"memberOf\": {\n",
        "    \"subject\": [\"Student\"],\n",
        "    \"object\": [\"ResearchGroup\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "# =====================================================\n",
        "# OUTPUT FORMAT\n",
        "# =====================================================\n",
        "\n",
        "Return ONLY a JSON LIST.\n",
        "Each item must be:\n",
        "\n",
        "{\n",
        "  \"node\": {...},\n",
        "  \"edges\": [\n",
        "     {\"relation\": \"...\", \"from\": \"...\", \"to\": \"...\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "No explanation.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEUF54hfIIN"
      },
      "source": [
        "Chunk Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efKrQbRLfE6h",
        "outputId": "fa4ae4ab-1f1e-48fa-b57a-9ee4e3131992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks: 48\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text, max_len=2000):\n",
        "    return [text[i:i+max_len] for i in range(0, len(text), max_len)]\n",
        "\n",
        "chunks = chunk_text(combined_text, 2000)\n",
        "print(\"Total chunks:\", len(chunks))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAPSyQhWfMgu"
      },
      "source": [
        "Run Groq + Extract KG According to Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IRtXtLHfJ2X",
        "outputId": "2e0b2877-0af3-4ad6-b891-6f4dae2bb874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing chunk 1/48\n",
            "\n",
            "Processing chunk 2/48\n",
            "\n",
            "Processing chunk 3/48\n",
            "\n",
            "Processing chunk 4/48\n",
            "\n",
            "Processing chunk 5/48\n",
            "\n",
            "Processing chunk 6/48\n",
            "\n",
            "Processing chunk 7/48\n",
            "\n",
            "Processing chunk 8/48\n",
            "\n",
            "Processing chunk 9/48\n",
            "\n",
            "Processing chunk 10/48\n",
            "\n",
            "Processing chunk 11/48\n",
            "\n",
            "Processing chunk 12/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 13/48\n",
            "\n",
            "Processing chunk 14/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 15/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 16/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 17/48\n",
            "\n",
            "Processing chunk 18/48\n",
            "\n",
            "Processing chunk 19/48\n",
            "\n",
            "Processing chunk 20/48\n",
            "\n",
            "Processing chunk 21/48\n",
            "\n",
            "Processing chunk 22/48\n",
            "\n",
            "Processing chunk 23/48\n",
            "\n",
            "Processing chunk 24/48\n",
            "\n",
            "Processing chunk 25/48\n",
            "\n",
            "Processing chunk 26/48\n",
            "\n",
            "Processing chunk 27/48\n",
            "\n",
            "Processing chunk 28/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 29/48\n",
            "\n",
            "Processing chunk 30/48\n",
            "\n",
            "Processing chunk 31/48\n",
            "\n",
            "Processing chunk 32/48\n",
            "\n",
            "Processing chunk 33/48\n",
            "\n",
            "Processing chunk 34/48\n",
            "\n",
            "Processing chunk 35/48\n",
            "\n",
            "Processing chunk 36/48\n",
            "\n",
            "Processing chunk 37/48\n",
            "\n",
            "Processing chunk 38/48\n",
            "\n",
            "Processing chunk 39/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 40/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 41/48\n",
            "\n",
            "Processing chunk 42/48\n",
            "\n",
            "Processing chunk 43/48\n",
            "\n",
            "Processing chunk 44/48\n",
            "\n",
            "Processing chunk 45/48\n",
            "⚠️ Invalid JSON → skipped\n",
            "\n",
            "Processing chunk 46/48\n",
            "\n",
            "Processing chunk 47/48\n",
            "\n",
            "Processing chunk 48/48\n"
          ]
        }
      ],
      "source": [
        "all_nodes = []\n",
        "all_edges = []\n",
        "\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    print(f\"\\nProcessing chunk {idx+1}/{len(chunks)}\")\n",
        "\n",
        "    prompt = schema_prompt + \"\\n\\n### TEXT ###\\n\" + chunk\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0,\n",
        "            max_tokens=2400\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"API ERROR:\", e)\n",
        "        continue\n",
        "\n",
        "    out = resp.choices[0].message.content\n",
        "    match = re.search(r\"\\[.*\\]\", out, re.DOTALL)\n",
        "\n",
        "    if not match:\n",
        "        print(\"⚠️ No JSON → skipped\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        data = json.loads(match.group(0))\n",
        "    except:\n",
        "        print(\"⚠️ Invalid JSON → skipped\")\n",
        "        continue\n",
        "\n",
        "    for item in data:\n",
        "        if \"node\" in item:\n",
        "            all_nodes.append(item[\"node\"])\n",
        "        for e in item.get(\"edges\", []):\n",
        "            all_edges.append(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddRt_tigfSGl"
      },
      "source": [
        "Deduplicate Nodes + Edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-n3yCnWfOuq",
        "outputId": "d3ff6b63-3691-44f3-a76e-be7aad63c792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Nodes: 206\n",
            "Final Edges: 249\n"
          ]
        }
      ],
      "source": [
        "unique_nodes = {}\n",
        "for n in all_nodes:\n",
        "    if \"id\" in n:\n",
        "        unique_nodes[n[\"id\"]] = n\n",
        "\n",
        "nodes = list(unique_nodes.values())\n",
        "\n",
        "seen = set()\n",
        "edges = []\n",
        "for e in all_edges:\n",
        "    if {\"from\",\"relation\",\"to\"} <= e.keys():\n",
        "        key = (e[\"from\"], e[\"relation\"], e[\"to\"])\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            edges.append(e)\n",
        "\n",
        "print(\"Final Nodes:\", len(nodes))\n",
        "print(\"Final Edges:\", len(edges))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5YmE4fkfW8e"
      },
      "source": [
        "Save Final KG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwqrflCOfXb5",
        "outputId": "a1abb1ee-dbee-49e0-ed91-6447815a1940"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved dse_kg.json\n",
            "Saved nodes.csv and edges.csv\n"
          ]
        }
      ],
      "source": [
        "json.dump({\"nodes\": nodes, \"edges\": edges}, open(\"dse_kg.json\",\"w\"), indent=2)\n",
        "print(\"Saved dse_kg.json\")\n",
        "\n",
        "pd.DataFrame(nodes).to_csv(\"nodes.csv\", index=False)\n",
        "pd.DataFrame(edges).to_csv(\"edges.csv\", index=False)\n",
        "\n",
        "print(\"Saved nodes.csv and edges.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
